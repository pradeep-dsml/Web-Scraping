{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Web Scraping NY Times.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr1j2aMiUsrr"
      },
      "source": [
        "# Web scraping NY times article in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts3Rpcz9Usr6"
      },
      "source": [
        "## Reading the web page into Python\n",
        "\n",
        "The first thing we need to do is to read the HTML for this article into Python, which we'll do using the [requests](http://docs.python-requests.org/en/master/) library. (If you don't have it, you can `pip install requests` from the command line.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "wMt5S3Z-Usr8"
      },
      "source": [
        "import requests\n",
        "r = requests.get('https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBYLuqwrUsr-"
      },
      "source": [
        "The code above fetches our web page from the URL, and stores the result in a \"response\" object called `r`. That response object has a `text` attribute, which contains the same HTML code we saw when viewing the source from our web browser:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PtDA7VxUsr_",
        "outputId": "ba5bd14d-2f40-4490-c6ed-60d78462d11a"
      },
      "source": [
        "# print the first 500 characters of the HTML\n",
        "print(r.text[0:500])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<!DOCTYPE html>\n",
            "<!--[if (gt IE 9)|!(IE)]> <!--><html lang=\"en\" class=\"no-js page-interactive section-opinion page-theme-standard tone-opinion page-interactive-default limit-small layout-xlarge app-interactive\" itemid=\"https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html\" itemtype=\"http://schema.org/NewsArticle\" itemscope xmlns:og=\"http://opengraphprotocol.org/schema/\"><!--<![endif]-->\n",
            "<!--[if IE 9]> <html lang=\"en\" class=\"no-js ie9 lt-ie10 page-interactive section-opinion page\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF4AIb6PUssA"
      },
      "source": [
        "## Parsing the HTML using Beautiful Soup\n",
        "\n",
        "We're going to parse the HTML using the [Beautiful Soup 4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library, which is a popular Python library for web scraping. (If you don't have it, you can `pip install beautifulsoup4` from the command line.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gN2dTpqEUssB"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(r.text, 'html.parser')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KljQ3BE6UssB"
      },
      "source": [
        "The code above parses the HTML (stored in `r.text`) into a special object called `soup` that the Beautiful Soup library understands. In other words, Beautiful Soup is **reading the HTML and making sense of its structure.**\n",
        "\n",
        "(Note that `html.parser` is the parser included with the Python standard library, though other parsers can be used by Beautiful Soup. See [differences between parsers](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#differences-between-parsers) to learn more.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hr4uGwtSUssC"
      },
      "source": [
        "results = soup.find_all('span', attrs={'class':'short-desc'})"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sPW9PqrUssD"
      },
      "source": [
        "This code searches the `soup` object for all `<span>` tags with the attribute `class=\"short-desc\"`. It returns a special Beautiful Soup object (called a \"ResultSet\") containing the search results.\n",
        "\n",
        "`results` acts like a **Python list**, so we can check its length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WRwIyf2UssE",
        "outputId": "a2f6c7c6-57a9-4593-e80f-98e8f77f9934"
      },
      "source": [
        "len(results)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk_DMMyVUssE"
      },
      "source": [
        "There are 116 results, which seems reasonable given the length of the article. (If this number did not seem reasonable, we would examine the HTML further to determine if our assumptions about the patterns in the HTML were incorrect.)\n",
        "\n",
        "We can also slice the object like a list, in order to examine the **first three results:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSkCGiBxUssF",
        "outputId": "1c6dab6a-abec-4de6-861f-b1c862990da8"
      },
      "source": [
        "results[0:3]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>,\n",
              " <span class=\"short-desc\"><strong>Jan. 21 </strong>“A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine.” <span class=\"short-truth\"><a href=\"http://nation.time.com/2013/11/06/10-things-you-didnt-know-about-time/\" target=\"_blank\">(Trump was on the cover 11 times and Nixon appeared 55 times.)</a></span></span>,\n",
              " <span class=\"short-desc\"><strong>Jan. 23 </strong>“Between 3 million and 5 million illegal votes caused me to lose the popular vote.” <span class=\"short-truth\"><a href=\"https://www.nytimes.com/2017/01/23/us/politics/donald-trump-congress-democrats.html\" target=\"_blank\">(There's no evidence of illegal voting.)</a></span></span>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4smwYyLXUssG",
        "outputId": "b6022733-ca47-445e-ef14-f244f9133d4c"
      },
      "source": [
        "results[-1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<span class=\"short-desc\"><strong>Nov. 11 </strong>“I'd rather have him  – you know, work with him on the Ukraine than standing and arguing about whether or not  – because that whole thing was set up by the Democrats.” <span class=\"short-truth\"><a href=\"https://www.nytimes.com/interactive/2017/12/10/us/politics/trump-and-russia.html\" target=\"_blank\">(There is no evidence that Democrats \"set up\" Russian interference in the election.)</a></span></span>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcv717emUssG"
      },
      "source": [
        "Looks good!\n",
        "\n",
        "We have now collected all 116 of the records, but we still need to **separate each record into its four components** (date, lie, explanation, and URL) in order to give the dataset some structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZpzHAtRUssH"
      },
      "source": [
        "## Extracting the date\n",
        "\n",
        "Web scraping is often an iterative process, in which you experiment with your code until it works exactly as you desire. To simplify the experimentation, we'll start by only working with the **first record** in the `results` object, and then later on we'll modify our code to use a loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5-mDR4EUssH",
        "outputId": "75addc6a-1de2-4b39-d352-786ea239ab32"
      },
      "source": [
        "first_result = results[0]\n",
        "first_result"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfsE8taLUssI"
      },
      "source": [
        "Although `first_result` may look like a Python string, you'll notice that there are no quote marks around it. Instead, it's another special Beautiful Soup object (called a \"Tag\") that has specific methods and attributes.\n",
        "\n",
        "In order to locate the date, we can use its `find()` method to **find a single tag** that matches a specific pattern, in contrast to the `find_all()` method we used above to **find all tags** that match a pattern:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXwMb6KMUssI",
        "outputId": "e7d2e8be-6ad7-4a41-c0b1-e358b5418bbc"
      },
      "source": [
        "first_result.find('strong')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<strong>Jan. 21 </strong>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9eg1MCeUssJ"
      },
      "source": [
        "This code searches `first_result` for the first instance of a `<strong>` tag, and again returns a Beautiful Soup \"Tag\" object (not a string).\n",
        "\n",
        "Since we want to **extract the text between the opening and closing tags**, we can access its `text` attribute, which does in fact return a regular Python string:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a2IsdR5WUssJ",
        "outputId": "c3967447-6acc-439f-d253-33bb4c024d8e"
      },
      "source": [
        "first_result.find('strong').text"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Jan. 21\\xa0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN4HWgGPUssN"
      },
      "source": [
        "What is `\\xa0`? You don't actually need to know this, but it's called an \"escape sequence\" that represents the `&nbsp;` character we saw earlier in the HTML source.\n",
        "\n",
        "However, you do need to know that **an escape sequence represents a single character** within a string. Let's slice it off from the end of the string:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "H5UIkS85UssO",
        "outputId": "e0e1850a-ebba-4569-f3b4-f3cff59db836"
      },
      "source": [
        "first_result.find('strong').text[0:-1]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Jan. 21'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoIYE_RCUssO"
      },
      "source": [
        "Finally, we're going to add the year, since we don't want our dataset to include ambiguous dates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "suqQKAw-UssO",
        "outputId": "c97a9bf2-d9fd-4412-ea98-749ef6171110"
      },
      "source": [
        "first_result.find('strong').text[0:-1] + ', 2017'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Jan. 21, 2017'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzgJGrMqUssP"
      },
      "source": [
        "## Extracting the lie\n",
        "\n",
        "Let's take another look at `first_result`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpRsF3UzUssP",
        "outputId": "879274a0-d821-46a7-bfef-576976bd357b"
      },
      "source": [
        "first_result"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgszAjF5UssQ"
      },
      "source": [
        "Our goal is to extract the two sentences about Iraq. Unfortunately, there isn't a pair of opening and closing tags that starts **immediately before the lie** and ends **immediately after the lie**. Therefore, we're going to have to use a different technique:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD5NJ24OUssQ",
        "outputId": "c75b8b58-58a4-4570-f5f3-fda5a86bbf8b"
      },
      "source": [
        "first_result.contents"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<strong>Jan. 21 </strong>,\n",
              " \"“I wasn't a fan of Iraq. I didn't want to go into Iraq.” \",\n",
              " <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U93sBfclUssR"
      },
      "source": [
        "The `first_result` \"Tag\" has a `contents` attribute, which returns a Python list containing its \"children\". What are children? They are the **Tags and strings that are nested within a Tag.**\n",
        "\n",
        "We can slice this list to extract the second element:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TmLVZeZ_UssR",
        "outputId": "a2eb74df-4a6a-4d0e-b0f2-32443835aa17"
      },
      "source": [
        "first_result.contents[1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"“I wasn't a fan of Iraq. I didn't want to go into Iraq.” \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbl-Rr2jUssR"
      },
      "source": [
        "Finally, we'll slice off the curly quotation marks as well as the extra space at the end:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xQzZbJmqUssS",
        "outputId": "41580e01-c3df-4f27-fa54-c2b5600f6edf"
      },
      "source": [
        "first_result.contents[1][1:-2]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I wasn't a fan of Iraq. I didn't want to go into Iraq.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueRGNn3DUssS"
      },
      "source": [
        "## Extracting the explanation\n",
        "\n",
        "Based upon what you've seen already, you might have figured out that we have at least **two options** for how we extract the third component of the record, which is the writer's explanation of why the President's statement was a lie.\n",
        "\n",
        "The **first option** is to slice the `contents` attribute, like we did when extracting the lie:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgMl2klmUssT",
        "outputId": "8e730c9c-309f-4ba1-ef7d-6fc1066bdaf5"
      },
      "source": [
        "first_result.contents[2]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwgNAVRFUssT"
      },
      "source": [
        "The **second option** is to search for the surrounding tag, like we did when extracting the date:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqLABFMTUssT",
        "outputId": "cbc37d6d-825e-4687-e415-6cf18ba27a11"
      },
      "source": [
        "first_result.find('a')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAvLFErXUssU"
      },
      "source": [
        "Either way, we can access the `text` attribute and then slice off the opening and closing parentheses:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y-E8J48xUssU",
        "outputId": "0352f8c7-f3a7-4f03-b955-64911ff02667"
      },
      "source": [
        "first_result.find('a').text[1:-1]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'He was for an invasion before he was against it.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6FpDDQAUssV"
      },
      "source": [
        "## Extracting the URL\n",
        "\n",
        "Finally, we want to extract the URL of the article that substantiates the writer's claim that the President was lying.\n",
        "\n",
        "Let's examine the `<a>` tag within `first_result`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVMEVICuUssV",
        "outputId": "bda69dfa-2a98-427a-c137-457e53d7e134"
      },
      "source": [
        "first_result.find('a')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HczlYJeuUssW"
      },
      "source": [
        "So far in this tutorial, we have been extracting text that is **between tags**. In this case, the text we want to extract is located **within the tag itself**. Specifically, we want to access the value of the `href` attribute within the `<a>` tag.\n",
        "\n",
        "Beautiful Soup treats tag attributes and their values like **key-value pairs in a dictionary:** you put the attribute name in brackets (like a dictionary key), and you get back the attribute's value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PjMjuatzUssW",
        "outputId": "a740572e-66cf-4842-90e4-3de26087926b"
      },
      "source": [
        "first_result.find('a')['href']"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2ZD5QZpUssX"
      },
      "source": [
        "## Building the dataset\n",
        "\n",
        "Now that we've figured out how to extract the four components of `first_result`, we can **create a loop to repeat this process** on all 116 `results`. We'll store the output in a **list of tuples** called `records`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "N2k88mjLUssX"
      },
      "source": [
        "records = []\n",
        "for result in results:\n",
        "    date = result.find('strong').text[0:-1] + ', 2017'\n",
        "    lie = result.contents[1][1:-2]\n",
        "    explanation = result.find('a').text[1:-1]\n",
        "    url = result.find('a')['href']\n",
        "    records.append((date, lie, explanation, url))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WfppSvdUssX"
      },
      "source": [
        "Since there were 116 `results`, we should have 116 `records`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKXo6QAjUssY",
        "outputId": "493e096f-d93e-4914-c515-193880abc298"
      },
      "source": [
        "len(records)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSX3pDDJUssY"
      },
      "source": [
        "Let's do a quick spot check of the first three records:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vPzhi0FUssZ",
        "outputId": "32597364-db36-447a-c428-18cb767f376d"
      },
      "source": [
        "records[0:3]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Jan. 21, 2017',\n",
              "  \"I wasn't a fan of Iraq. I didn't want to go into Iraq.\",\n",
              "  'He was for an invasion before he was against it.',\n",
              "  'https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the'),\n",
              " ('Jan. 21, 2017',\n",
              "  'A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine.',\n",
              "  'Trump was on the cover 11 times and Nixon appeared 55 times.',\n",
              "  'http://nation.time.com/2013/11/06/10-things-you-didnt-know-about-time/'),\n",
              " ('Jan. 23, 2017',\n",
              "  'Between 3 million and 5 million illegal votes caused me to lose the popular vote.',\n",
              "  \"There's no evidence of illegal voting.\",\n",
              "  'https://www.nytimes.com/2017/01/23/us/politics/donald-trump-congress-democrats.html')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtpEQyUUUssZ"
      },
      "source": [
        "Looks good!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2HWEfn4Ussa"
      },
      "source": [
        "## Applying a tabular data structure\n",
        "\n",
        "The last major step in this process is to apply a tabular data structure to our existing structure (which is a list of tuples). We're going to do this using the [pandas](http://pandas.pydata.org/) library, an incredibly popular Python library for data analysis and manipulation.\n",
        "\n",
        "The primary data structure in pandas is the \"DataFrame\", which is suitable for tabular data with columns of different types, **similar to an Excel spreadsheet or SQL table.** We can convert our list of tuples into a DataFrame by passing it to the DataFrame constructor and specifying the desired column names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hKutnU_uUssa"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(records, columns=['date', 'lie', 'explanation', 'url'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYOZKaB_Ussb"
      },
      "source": [
        "The DataFrame includes a `head()` method, which allows you to examine the top of the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xlrIV7s-Ussb",
        "outputId": "cd75f2b8-4def-4b14-c118-aa02d00da632"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>lie</th>\n",
              "      <th>explanation</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jan. 21, 2017</td>\n",
              "      <td>I wasn't a fan of Iraq. I didn't want to go in...</td>\n",
              "      <td>He was for an invasion before he was against it.</td>\n",
              "      <td>https://www.buzzfeed.com/andrewkaczynski/in-20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jan. 21, 2017</td>\n",
              "      <td>A reporter for Time magazine — and I have been...</td>\n",
              "      <td>Trump was on the cover 11 times and Nixon appe...</td>\n",
              "      <td>http://nation.time.com/2013/11/06/10-things-yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jan. 23, 2017</td>\n",
              "      <td>Between 3 million and 5 million illegal votes ...</td>\n",
              "      <td>There's no evidence of illegal voting.</td>\n",
              "      <td>https://www.nytimes.com/2017/01/23/us/politics...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jan. 25, 2017</td>\n",
              "      <td>Now, the audience was the biggest ever. But th...</td>\n",
              "      <td>Official aerial photos show Obama's 2009 inaug...</td>\n",
              "      <td>https://www.nytimes.com/2017/01/21/us/politics...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jan. 25, 2017</td>\n",
              "      <td>Take a look at the Pew reports (which show vot...</td>\n",
              "      <td>The report never mentioned voter fraud.</td>\n",
              "      <td>https://www.nytimes.com/2017/01/24/us/politics...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  ...                                                url\n",
              "0  Jan. 21, 2017  ...  https://www.buzzfeed.com/andrewkaczynski/in-20...\n",
              "1  Jan. 21, 2017  ...  http://nation.time.com/2013/11/06/10-things-yo...\n",
              "2  Jan. 23, 2017  ...  https://www.nytimes.com/2017/01/23/us/politics...\n",
              "3  Jan. 25, 2017  ...  https://www.nytimes.com/2017/01/21/us/politics...\n",
              "4  Jan. 25, 2017  ...  https://www.nytimes.com/2017/01/24/us/politics...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGVvAbUlUssc"
      },
      "source": [
        "The numbers on the left side of the DataFrame are known as the \"index\", which act as identifiers for the rows. Because we didn't specify an index, it was automatically assigned as the integers 0 to 115.\n",
        "\n",
        "We can examine the bottom of the DataFrame using the `tail()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "M6BmFFDRUssc",
        "outputId": "f84522da-a6eb-4385-ba45-c15f4197c1b4"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>lie</th>\n",
              "      <th>explanation</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>Oct. 25, 2017</td>\n",
              "      <td>We have trade deficits with almost everybody.</td>\n",
              "      <td>We have trade surpluses with more than 100 cou...</td>\n",
              "      <td>https://www.bea.gov/newsreleases/international...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>Oct. 27, 2017</td>\n",
              "      <td>Wacky &amp; totally unhinged Tom Steyer, who has b...</td>\n",
              "      <td>Steyer has financially supported many winning ...</td>\n",
              "      <td>https://www.opensecrets.org/donor-lookup/resul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>Nov. 1, 2017</td>\n",
              "      <td>Again, we're the highest-taxed nation, just ab...</td>\n",
              "      <td>We're not.</td>\n",
              "      <td>http://www.politifact.com/truth-o-meter/statem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>Nov. 7, 2017</td>\n",
              "      <td>When you look at the city with the strongest g...</td>\n",
              "      <td>Several other cities, including New York and L...</td>\n",
              "      <td>http://www.politifact.com/truth-o-meter/statem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>Nov. 11, 2017</td>\n",
              "      <td>I'd rather have him  – you know, work with him...</td>\n",
              "      <td>There is no evidence that Democrats \"set up\" R...</td>\n",
              "      <td>https://www.nytimes.com/interactive/2017/12/10...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              date  ...                                                url\n",
              "175  Oct. 25, 2017  ...  https://www.bea.gov/newsreleases/international...\n",
              "176  Oct. 27, 2017  ...  https://www.opensecrets.org/donor-lookup/resul...\n",
              "177   Nov. 1, 2017  ...  http://www.politifact.com/truth-o-meter/statem...\n",
              "178   Nov. 7, 2017  ...  http://www.politifact.com/truth-o-meter/statem...\n",
              "179  Nov. 11, 2017  ...  https://www.nytimes.com/interactive/2017/12/10...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48GZWjyKUssd"
      },
      "source": [
        "Did you notice that \"January\" is abbreviated, while \"July\" is not? It's best to format your data consistently, and so we're going to convert the date column to pandas' special \"datetime\" format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CO8UKbJsUssd"
      },
      "source": [
        "df['date'] = pd.to_datetime(df['date'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58MnAvyNUssd"
      },
      "source": [
        "The code above converts the \"date\" column to datetime format, and then overwrites the existing \"date\" column. (Notice that we did not have to tell pandas that the column was originally in \"MONTH DAY, YEAR\" format - **pandas just figured it out!**)\n",
        "\n",
        "Let's take a look at the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OizIi2wlUsse",
        "outputId": "42e89366-f847-44b3-c633-24d472ecc2f9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>lie</th>\n",
              "      <th>explanation</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-21</td>\n",
              "      <td>I wasn't a fan of Iraq. I didn't want to go in...</td>\n",
              "      <td>He was for an invasion before he was against it.</td>\n",
              "      <td>https://www.buzzfeed.com/andrewkaczynski/in-20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-21</td>\n",
              "      <td>A reporter for Time magazine — and I have been...</td>\n",
              "      <td>Trump was on the cover 11 times and Nixon appe...</td>\n",
              "      <td>http://nation.time.com/2013/11/06/10-things-yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-23</td>\n",
              "      <td>Between 3 million and 5 million illegal votes ...</td>\n",
              "      <td>There's no evidence of illegal voting.</td>\n",
              "      <td>https://www.nytimes.com/2017/01/23/us/politics...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-25</td>\n",
              "      <td>Now, the audience was the biggest ever. But th...</td>\n",
              "      <td>Official aerial photos show Obama's 2009 inaug...</td>\n",
              "      <td>https://www.nytimes.com/2017/01/21/us/politics...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-25</td>\n",
              "      <td>Take a look at the Pew reports (which show vot...</td>\n",
              "      <td>The report never mentioned voter fraud.</td>\n",
              "      <td>https://www.nytimes.com/2017/01/24/us/politics...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        date  ...                                                url\n",
              "0 2017-01-21  ...  https://www.buzzfeed.com/andrewkaczynski/in-20...\n",
              "1 2017-01-21  ...  http://nation.time.com/2013/11/06/10-things-yo...\n",
              "2 2017-01-23  ...  https://www.nytimes.com/2017/01/23/us/politics...\n",
              "3 2017-01-25  ...  https://www.nytimes.com/2017/01/21/us/politics...\n",
              "4 2017-01-25  ...  https://www.nytimes.com/2017/01/24/us/politics...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "60_O-8jgUsse",
        "outputId": "871424a4-582d-4741-b204-4906fff7d600"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>lie</th>\n",
              "      <th>explanation</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>2017-10-25</td>\n",
              "      <td>We have trade deficits with almost everybody.</td>\n",
              "      <td>We have trade surpluses with more than 100 cou...</td>\n",
              "      <td>https://www.bea.gov/newsreleases/international...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>2017-10-27</td>\n",
              "      <td>Wacky &amp; totally unhinged Tom Steyer, who has b...</td>\n",
              "      <td>Steyer has financially supported many winning ...</td>\n",
              "      <td>https://www.opensecrets.org/donor-lookup/resul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>2017-11-01</td>\n",
              "      <td>Again, we're the highest-taxed nation, just ab...</td>\n",
              "      <td>We're not.</td>\n",
              "      <td>http://www.politifact.com/truth-o-meter/statem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>2017-11-07</td>\n",
              "      <td>When you look at the city with the strongest g...</td>\n",
              "      <td>Several other cities, including New York and L...</td>\n",
              "      <td>http://www.politifact.com/truth-o-meter/statem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>I'd rather have him  – you know, work with him...</td>\n",
              "      <td>There is no evidence that Democrats \"set up\" R...</td>\n",
              "      <td>https://www.nytimes.com/interactive/2017/12/10...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  ...                                                url\n",
              "175 2017-10-25  ...  https://www.bea.gov/newsreleases/international...\n",
              "176 2017-10-27  ...  https://www.opensecrets.org/donor-lookup/resul...\n",
              "177 2017-11-01  ...  http://www.politifact.com/truth-o-meter/statem...\n",
              "178 2017-11-07  ...  http://www.politifact.com/truth-o-meter/statem...\n",
              "179 2017-11-11  ...  https://www.nytimes.com/interactive/2017/12/10...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEuR3ywgUssf"
      },
      "source": [
        "Not only is the date column now consistently formatted, but pandas also provides a wealth of [date-related functionality](https://pandas.pydata.org/pandas-docs/stable/timeseries.html) because it's in datetime format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq-ZdeGfUssf"
      },
      "source": [
        "## Exporting the dataset to a CSV file\n",
        "\n",
        "Finally, we'll use pandas to export the DataFrame to a CSV (comma-separated value) file, which is the simplest and most common way to **store tabular data in a text file:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "L4JrnFiwUssf"
      },
      "source": [
        "df.to_csv('trump_lies.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FlnI1cgUssg"
      },
      "source": [
        "We set the `index` parameter to `False` to tell pandas that we don't need it to include the index (the integers 0 to 115) in the CSV file. You should be able to find this file in your working directory, and open it in any text editor or spreadsheet program!\n",
        "\n",
        "In the future, you can rebuild this DataFrame by reading the CSV file back into pandas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "0jiaoHzUUssg"
      },
      "source": [
        "df = pd.read_csv('trump_lies.csv', parse_dates=['date'], encoding='utf-8')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoF9MY_EUssh"
      },
      "source": [
        "## Summary: 16 lines of Python code\n",
        "\n",
        "Here are the 16 lines of code that we used to scrape the web page, extract the relevant data, convert it into a tabular dataset, and export it to a CSV file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "U_SmXdrrUssh"
      },
      "source": [
        "import requests\n",
        "r = requests.get('https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html')\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "results = soup.find_all('span', attrs={'class':'short-desc'})\n",
        "\n",
        "records = []\n",
        "for result in results:\n",
        "    date = result.find('strong').text[0:-1] + ', 2017'\n",
        "    lie = result.contents[1][1:-2]\n",
        "    explanation = result.find('a').text[1:-1]\n",
        "    url = result.find('a')['href']\n",
        "    records.append((date, lie, explanation, url))\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(records, columns=['date', 'lie', 'explanation', 'url'])\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.to_csv('trump_lies.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}
